# Delete kubernetes cluster node.
# This is best effort. Reboot may be required to remove excess veth network devices.
# Cri-o pods can get confused after repeated cluster creates and deletes. And so forth.
---
- name: Get kubernetes cluster facts
  ansible.builtin.import_playbook: kc_facts.yaml
- name: Delete kubernetes cluster node
  hosts: all
  gather_facts: true
  become: true
  vars_files:
    - vars/vars_vault.yaml
  vars:
    ansible_ssh_password: "{{ kc_ssh_password }}"
    ansible_become_password: "{{ kc_become_password }}"
  tasks:
# Try to "clean" kubernetes node
    - name: Drain node
      ansible.builtin.command: "kubectl drain {{ inventory_hostname_short }} --force --grace-period=10"
      ignore_errors: true
# kubeadm reset
# Reset stops and disables kubelet service
    - name: Run kubeadm reset
      ansible.builtin.include_role:
        name: kcsetup_inet
        tasks_from: run_kubereset
    - name: Delete leftover calico CNI configuration
      ansible.builtin.include_role:
        name: kcsetup_inet
        tasks_from: delete_calico
# Delete node from cluster
# Kublet recreates its node object if delete is run before reset
    - name: Delete node
      ansible.builtin.command: "kubectl delete node {{ inventory_hostname_short }}"
      ignore_errors: true
      delegate_to: '{{ hostvars["K8S_VARS"]["kc_control_name"] }}'
